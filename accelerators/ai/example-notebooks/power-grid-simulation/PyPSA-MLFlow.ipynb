{
 "cells": [
  {
   "attachments": {
    "639f7fce-8adb-42fd-a2ff-a27c54296983.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "781f7cd5-630d-4e7e-a204-7ff88d1c47ac",
   "metadata": {},
   "source": [
    "<img width=\"60px\" style=\"float: right;\" src=\"https://xmks.s3.amazonaws.com/2020/X-Blue.png\">\n",
    "\n",
    "![icons8-power-line-64.png](attachment:639f7fce-8adb-42fd-a2ff-a27c54296983.png)\n",
    "# Power Grid: Create a model that can be used for simulation as well as real-time monitoring for grid load\n",
    "\n",
    "## Importing Necessary Libraries\n",
    "\n",
    "Firstly, we need to import all the necessary libraries that will be used throughout the code.\n",
    "\n",
    "The libraries include `pypsa` for power system simulations, `numpy` and `pandas` for numerical calculations and data manipulation, `json` for handling JSON data, `requests` and `urllib.parse` for making HTTP requests, and `functools` for higher-order functions and operations on callable objects. Lastly, we import `mlflow` for Machine Learning Lifecycle management.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bbe974-bbab-43e6-8cbe-32fd8fdd2c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pypsa --quiet\n",
    "import pypsa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "from functools import reduce\n",
    "import requests\n",
    "import mlflow\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda93f64-dde7-49c2-b216-ba522d1c72fb",
   "metadata": {},
   "source": [
    "# Create Network\n",
    "\n",
    "Next, we define a function named `powerflow_analysis` that will take input as data and perform power flow analysis using the PyPSA library. \n",
    "\n",
    "This function creates a network of buses, loads, generators, and lines based on the input data. The power flow analysis is then performed on this network. The result of the analysis is a dictionary of calculated metrics, which are returned as a GeoJSON string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1c3c04-f4f8-4650-b357-61603c745b36",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def powerflow_analysis(data):\n",
    "    \n",
    "    data = str(data['input'].values[0])\n",
    "    \n",
    "    # Load the data string as a json\n",
    "    data = json.loads(data)\n",
    "    \n",
    "    # Print the data for debugging purposes\n",
    "    print(data)\n",
    "    \n",
    "    # Create a new Network object\n",
    "    network = pypsa.Network()\n",
    "\n",
    "    # Add buses and loads to the network from the data\n",
    "    for item in data['features']:\n",
    "        if item['properties']['type']=='Bus':\n",
    "            network.add(\"Bus\", \n",
    "                        item['properties']['Id'], \n",
    "                        v_nom=item['properties']['BaseKV'],\n",
    "                        x=item['geometry']['coordinates'][0],\n",
    "                        y=item['geometry']['coordinates'][1],\n",
    "                        control=item['properties']['Bus Type'])\n",
    "            \n",
    "            # Adding loads to the network\n",
    "            network.add(\"Load\",\n",
    "                        f\"Load{item['properties']['Id']}\",\n",
    "                        bus=item['properties']['Id'],\n",
    "                        p_set=item['properties']['MW Load'])\n",
    "\n",
    "    # Add generators to the network from the data\n",
    "    for item in data['features']:\n",
    "        if item['properties']['type']=='Generator':\n",
    "            network.add(\"Generator\", \n",
    "                        item['properties']['Id'],\n",
    "                        bus=item['properties']['Bus ID'],\n",
    "                        p_set=item['properties']['MW Inj'],\n",
    "                        control=\"PQ\")\n",
    "\n",
    "    # Add lines to the network from the data\n",
    "    for item in data['features']:\n",
    "        if item['properties']['type']=='Line':\n",
    "            network.add(\n",
    "                \"Line\",\n",
    "                item['properties']['Id'],\n",
    "                bus0=item['properties']['From Bus'],\n",
    "                bus1=item['properties']['To Bus'],\n",
    "                x=item['properties']['X'],\n",
    "                r=item['properties']['R'])\n",
    "            \n",
    "    # Run Power Flow Analysis on the network\n",
    "    network.pf()\n",
    "    \n",
    "    # Build metrics for lines, buses, and generators\n",
    "    _dfs_lines = []\n",
    "    _dfs_buses = []\n",
    "    _dfs_generators = []\n",
    "\n",
    "    for k, v in network.lines_t.items():\n",
    "        _df = v.melt(ignore_index=False).reset_index().iloc[:,1:]\n",
    "        _df = _df.rename(columns={_df.columns[-1]: k})\n",
    "        _dfs_lines.append(_df)\n",
    "\n",
    "    for k, v in network.buses_t.items():\n",
    "        _df = v.melt(ignore_index=False).reset_index().iloc[:,1:]\n",
    "        _df = _df.rename(columns={_df.columns[-1]: k})\n",
    "        _dfs_buses.append(_df)\n",
    "\n",
    "    for k, v in network.generators_t.items():\n",
    "        _df = v.melt(ignore_index=False).reset_index().iloc[:,1:]\n",
    "        _df = _df.rename(columns={_df.columns[-1]: k})\n",
    "        _dfs_generators.append(_df)\n",
    "        \n",
    "    # Combine all metrics dataframe for lines\n",
    "    df_lines = reduce(lambda left,right: pd.DataFrame.combine_first(left,right), _dfs_lines)\n",
    "    df_lines = df_lines.set_index('variable')\n",
    "    df_lines = df_lines.dropna(axis=1, how='all').T.to_dict()\n",
    "    \n",
    "    # Combine all metrics dataframe for buses\n",
    "    df_buses = reduce(lambda left,right: pd.DataFrame.combine_first(left,right), _dfs_buses)\n",
    "    df_buses = df_buses.set_index('Bus')\n",
    "    df_buses = df_buses.dropna(axis=1, how='all').T.to_dict()\n",
    "    \n",
    "    # Combine all metrics dataframe for generators\n",
    "    df_generators = reduce(lambda left,right: pd.DataFrame.combine_first(left,right), _dfs_generators)\n",
    "    df_generators = df_generators.set_index('Generator')\n",
    "    df_generators = df_generators.dropna(axis=1, how='all').T.to_dict()\n",
    "    \n",
    "    # Update Data with the power flow analysis results\n",
    "    for item in data['features']:\n",
    "        _id = item['properties']['Id']\n",
    "        if _id in df_lines:\n",
    "            _addin = df_lines[_id]\n",
    "            item['properties'].update(_addin)\n",
    "\n",
    "        if _id in df_buses:\n",
    "            _addin = df_buses[_id]\n",
    "            item['properties'].update(_addin)\n",
    "\n",
    "        if _id in df_generators:\n",
    "            _addin = df_generators[_id]\n",
    "            item['properties'].update(_addin)\n",
    "    \n",
    "    # Return the updated data as a list of json objects - this is required for the MLFlow response\n",
    "    return [json.dumps(data)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd52d1-98fd-43aa-8a66-44f9d06237bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Deployment\n",
    "\n",
    "In the following code block, we save and deploy our model using `mlflow`.\n",
    "\n",
    "We first define a model signature that defines the input and output data schema for our model. Then we create a subclass of `mlflow.pyfunc.PythonModel` where we override the `predict` function.\n",
    "\n",
    "We then specify the MLFlow tracking URI and start a new MLFlow run. The model is logged to this run and then registered in MLFlow's model registry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068be3b3-2d7e-46aa-8f14-358c95a4bf07",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>NOTE:</b> Set the specific IP address and port for your MLFlow server</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0afa42a-35b8-4cc0-bbab-1fe80aac99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'PowerFlowAnalysis_5b' already exists. Creating a new version of this model...\n",
      "2023/07/13 04:21:46 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: PowerFlowAnalysis_5b, version 11\n",
      "Created version '11' of model 'PowerFlowAnalysis_5b'.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, Schema\n",
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "\n",
    "# Define a schema for the input and output of your model\n",
    "# In this case, both input and output are single columns of string type\n",
    "sig = ModelSignature(\n",
    "        inputs=Schema([ColSpec(name=\"input\", type=\"string\")]),\n",
    "        outputs=Schema([ColSpec(name=\"output\", type=\"string\")]),\n",
    "    )\n",
    "\n",
    "# Define a new class that inherits from mlflow.pyfunc.PythonModel\n",
    "# This is necessary to define the predict function for your model\n",
    "class PowerFlowModel(mlflow.pyfunc.PythonModel):\n",
    "    def predict(self, context, model_input):\n",
    "        # Call the powerflow_analysis function defined earlier to predict on the model_input\n",
    "        return powerflow_analysis(model_input)\n",
    "\n",
    "# Set the tracking URI for MLflow\n",
    "# This is the address where the MLflow server is running\n",
    "# Replace the IP address and port number with the ones for your server\n",
    "mlflow.set_tracking_uri('http://IPADDRESS:5000')\n",
    "\n",
    "# Start a new MLflow run\n",
    "# This represents a single execution of the model training code\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Specify the model path\n",
    "    model_path = \"model\"\n",
    "    \n",
    "    # Log the model\n",
    "    # This saves the model in a format that can be loaded later for further use\n",
    "    # 'python_model' specifies the Python model to log\n",
    "    # 'signature' specifies the input and output schema of the model\n",
    "    mlflow.pyfunc.log_model(\n",
    "        model_path,\n",
    "        python_model=PowerFlowModel(),\n",
    "        signature=sig\n",
    "    )\n",
    "\n",
    "    # Register the model in MLflow's model registry\n",
    "    # This makes the model easily accessible from anywhere in the MLflow environment\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/{model_path}\"\n",
    "    registered_model_name = \"PowerFlowAnalysis\"\n",
    "    mlflow.register_model(model_uri, registered_model_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
